Traceback (most recent call last):
  File "/home/seanc/.local/lib/python3.8/site-packages/jupyter_cache/executors/utils.py", line 51, in single_nb_execution
    executenb(
  File "/home/seanc/.local/lib/python3.8/site-packages/nbclient/client.py", line 1093, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "/home/seanc/.local/lib/python3.8/site-packages/nbclient/util.py", line 84, in wrapped
    return just_run(coro(*args, **kwargs))
  File "/home/seanc/.local/lib/python3.8/site-packages/nbclient/util.py", line 62, in just_run
    return loop.run_until_complete(coro)
  File "/usr/lib/python3.8/asyncio/base_events.py", line 616, in run_until_complete
    return future.result()
  File "/home/seanc/.local/lib/python3.8/site-packages/nbclient/client.py", line 559, in async_execute
    await self.async_execute_cell(
  File "/home/seanc/.local/lib/python3.8/site-packages/nbclient/client.py", line 854, in async_execute_cell
    self._check_raise_for_error(cell, exec_reply)
  File "/home/seanc/.local/lib/python3.8/site-packages/nbclient/client.py", line 756, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
# Let's define our schema
schema = StructType([\
    StructField("date", DateType(), True),\
    StructField("time", StringType(), True),\
    StructField("company", StringType(), True),\
    StructField("level", StringType(), True),\
    StructField("title", StringType(), True),\
    StructField("totalyearlycompensation", IntegerType(), False),\
    StructField("location", StringType(), True),\
    StructField("yearsofexperience", FloatType(), False),\
    StructField("yearsatcompany", FloatType(), False),\
    StructField("tag", StringType(), True),\
    StructField("basesalary", IntegerType(), False),\
    StructField("stockgrantvalue", IntegerType(), False),\
    StructField("bonus", IntegerType(), False),\
    StructField("gender", StringType(), True),\
    StructField("cityid", StringType(), True),\
    StructField("dmaid", StringType(), True),\
    StructField("race", StringType(), True),\
    StructField("education", StringType(), True)])

# Load and parse the data file, converting it to a DataFrame.
data = spark.read.format("csv")\
    .option("header", "false")\
    .option("delimiter", "\t")\
    .schema(schema)\
    .load("data/seperated_time_data/cleaned.txt")
------------------

[0;31m---------------------------------------------------------------------------[0m
[0;31mAnalysisException[0m                         Traceback (most recent call last)
[0;32m<ipython-input-4-bcd561ea877c>[0m in [0;36m<module>[0;34m[0m
[1;32m     21[0m [0;34m[0m[0m
[1;32m     22[0m [0;31m# Load and parse the data file, converting it to a DataFrame.[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 23[0;31m [0mdata[0m [0;34m=[0m [0mspark[0m[0;34m.[0m[0mread[0m[0;34m.[0m[0mformat[0m[0;34m([0m[0;34m"csv"[0m[0;34m)[0m[0;31m\[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     24[0m     [0;34m.[0m[0moption[0m[0;34m([0m[0;34m"header"[0m[0;34m,[0m [0;34m"false"[0m[0;34m)[0m[0;31m\[0m[0;34m[0m[0;34m[0m[0m
[1;32m     25[0m     [0;34m.[0m[0moption[0m[0;34m([0m[0;34m"delimiter"[0m[0;34m,[0m [0;34m"\t"[0m[0;34m)[0m[0;31m\[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/spark/python/pyspark/sql/readwriter.py[0m in [0;36mload[0;34m(self, path, format, schema, **options)[0m
[1;32m    202[0m         [0mself[0m[0;34m.[0m[0moptions[0m[0;34m([0m[0;34m**[0m[0moptions[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m    203[0m         [0;32mif[0m [0misinstance[0m[0;34m([0m[0mpath[0m[0;34m,[0m [0mstr[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 204[0;31m             [0;32mreturn[0m [0mself[0m[0;34m.[0m[0m_df[0m[0;34m([0m[0mself[0m[0;34m.[0m[0m_jreader[0m[0;34m.[0m[0mload[0m[0;34m([0m[0mpath[0m[0;34m)[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    205[0m         [0;32melif[0m [0mpath[0m [0;32mis[0m [0;32mnot[0m [0;32mNone[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    206[0m             [0;32mif[0m [0mtype[0m[0;34m([0m[0mpath[0m[0;34m)[0m [0;34m!=[0m [0mlist[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py[0m in [0;36m__call__[0;34m(self, *args)[0m
[1;32m   1302[0m [0;34m[0m[0m
[1;32m   1303[0m         [0manswer[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0mgateway_client[0m[0;34m.[0m[0msend_command[0m[0;34m([0m[0mcommand[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 1304[0;31m         return_value = get_return_value(
[0m[1;32m   1305[0m             answer, self.gateway_client, self.target_id, self.name)
[1;32m   1306[0m [0;34m[0m[0m

[0;32m/usr/local/spark/python/pyspark/sql/utils.py[0m in [0;36mdeco[0;34m(*a, **kw)[0m
[1;32m    115[0m                 [0;31m# Hide where the exception came from that shows a non-Pythonic[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m
[1;32m    116[0m                 [0;31m# JVM exception message.[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m
[0;32m--> 117[0;31m                 [0;32mraise[0m [0mconverted[0m [0;32mfrom[0m [0;32mNone[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m    118[0m             [0;32melse[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m    119[0m                 [0;32mraise[0m[0;34m[0m[0;34m[0m[0m

[0;31mAnalysisException[0m: Path does not exist: file:/home/seanc/ca4022_assignment_3/docs/book/data/seperated_time_data/cleaned.txt
AnalysisException: Path does not exist: file:/home/seanc/ca4022_assignment_3/docs/book/data/seperated_time_data/cleaned.txt

